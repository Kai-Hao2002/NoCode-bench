# Generated by Django 5.2.7 on 2025-11-02 21:35

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='EvaluationTask',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('nocode_bench_id', models.CharField(help_text='e.g. example-repo/task-001', max_length=255, unique=True)),
                ('doc_change_input', models.TextField(help_text='The documentation change instruction.')),
                ('ground_truth_patch', models.TextField(blank=True, help_text='The ground-truth diff patch from the dataset.', null=True)),
                ('feature_test_patch', models.TextField(help_text="The ground-truth test patch (from 'test_patch').")),
                ('f2p_test_names', models.JSONField(default=list, help_text='List of FAIL2PASS test names.')),
                ('p2p_test_names', models.JSONField(default=list, help_text='List of PASS2PASS test names (regression tests).')),
                ('status', models.CharField(choices=[('PENDING', 'Pending'), ('RUNNING', 'Running'), ('COMPLETED', 'Completed'), ('FAILED', 'Failed'), ('FAILED_APPLY', 'Failed_Apply'), ('FAILED_TEST', 'Failed_Test')], default='PENDING', max_length=20)),
                ('celery_task_id', models.CharField(blank=True, max_length=255, null=True)),
                ('start_time', models.DateTimeField(auto_now_add=True)),
                ('end_time', models.DateTimeField(blank=True, null=True)),
                ('error_details', models.TextField(blank=True, null=True)),
            ],
        ),
        migrations.CreateModel(
            name='EvaluationResult',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('success_percent', models.FloatField(default=0.0)),
                ('applied_percent', models.FloatField(default=0.0)),
                ('rt_percent', models.FloatField(default=0.0)),
                ('fv_macro', models.FloatField(default=0.0)),
                ('file_percent', models.FloatField(default=0.0)),
                ('num_token', models.IntegerField(default=0)),
                ('run_time_seconds', models.FloatField(default=0.0)),
                ('f2p_passed_count', models.IntegerField(default=0)),
                ('f2p_total_count', models.IntegerField(default=0)),
                ('generated_patch', models.TextField(help_text='The code patch generated by the LLM.')),
                ('task', models.OneToOneField(on_delete=django.db.models.deletion.CASCADE, related_name='result', to='agent_core.evaluationtask')),
            ],
        ),
        migrations.CreateModel(
            name='EvaluationAttempt',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('attempt_number', models.IntegerField()),
                ('status', models.CharField(choices=[('APPLY_FAILED', 'Apply Failed'), ('TEST_FAILED', 'Test Failed'), ('PASSED', 'Passed')], max_length=20)),
                ('prompt_text', models.TextField(help_text='發送給 LLM 的完整提示')),
                ('raw_response', models.TextField(help_text='來自 LLM 的原始回應')),
                ('generated_patch', models.TextField(help_text='該次嘗試生成的 git diff')),
                ('test_output', models.TextField(help_text='Pytest 的輸出日誌')),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('task', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='attempts', to='agent_core.evaluationtask')),
            ],
            options={
                'ordering': ['attempt_number'],
            },
        ),
    ]
