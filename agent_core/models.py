# agent_core/models.py
from django.db import models

class EvaluationTask(models.Model):
    STATUS_CHOICES = [
        ('PENDING', 'Pending'),
        ('RUNNING', 'Running'),
        ('COMPLETED', 'Completed'),
        ('FAILED', 'Failed'),
    ]

    # NoCode-bench 實例 ID，用於查找程式碼庫
    nocode_bench_id = models.CharField(max_length=255, unique=True, help_text="e.g. example-repo/task-001")
    doc_change_input = models.TextField(help_text="The documentation change instruction.")
    
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='PENDING')
    celery_task_id = models.CharField(max_length=255, null=True, blank=True)
    
    start_time = models.DateTimeField(auto_now_add=True)
    end_time = models.DateTimeField(null=True, blank=True)
    error_details = models.TextField(null=True, blank=True)

    def __str__(self):
        return f"Task: {self.nocode_bench_id} - {self.status}"

class EvaluationResult(models.Model):
    task = models.OneToOneField(EvaluationTask, on_delete=models.CASCADE, related_name='result')
    
    # 必需指標
    success_percent = models.FloatField(default=0.0)
    applied_percent = models.FloatField(default=0.0)
    rt_percent = models.FloatField(default=0.0)
    fv_micro = models.FloatField(default=0.0)
    fv_macro = models.FloatField(default=0.0)
    file_percent = models.FloatField(default=0.0)
    num_token = models.IntegerField(default=0)
    
    # 輸出
    generated_patch = models.TextField(help_text="The code patch generated by the LLM.")
    
    # ... 其他可選指標