# agent_core/models.py
from django.db import models

class EvaluationTask(models.Model):
    STATUS_CHOICES = [
        ('PENDING', 'Pending'),
        ('RUNNING', 'Running'),
        ('COMPLETED', 'Completed'),
        ('FAILED', 'Failed'),
        ('FAILED_APPLY', 'Failed_Apply'), # æ‡‰ç”¨å¤±æ•— (Apply failed)
        ('FAILED_TEST', 'Failed_Test'),      # æ¸¬è©¦å¤±æ•— (Test failed)
    ]

    # NoCode-bench å¯¦ä¾‹ IDï¼Œç”¨æ–¼æŸ¥æ‰¾ç¨‹å¼ç¢¼åº«
    nocode_bench_id = models.CharField(max_length=255, unique=True, help_text="e.g. example-repo/task-001")
    doc_change_input = models.TextField(help_text="The documentation change instruction.")
    
    ground_truth_patch = models.TextField(help_text="The ground-truth diff patch from the dataset.", null=True, blank=True)

    feature_test_patch = models.TextField(help_text="The ground-truth test patch (from 'test_patch').")
    f2p_test_names = models.JSONField(default=list, help_text="List of FAIL2PASS test names.")
    p2p_test_names = models.JSONField(default=list, help_text="List of PASS2PASS test names (regression tests).")
    
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='PENDING')
    celery_task_id = models.CharField(max_length=255, null=True, blank=True)
    
    start_time = models.DateTimeField(auto_now_add=True)
    end_time = models.DateTimeField(null=True, blank=True)
    error_details = models.TextField(null=True, blank=True)

    def __str__(self):
        return f"Task: {self.nocode_bench_id} - {self.status}"

class EvaluationAttempt(models.Model):
    STATUS_CHOICES = [
        ('APPLY_FAILED', 'Apply Failed'), # AI æ ¼å¼éŒ¯èª¤ (AI format error)
        ('TEST_FAILED', 'Test Failed'),   # ç¨‹å¼ç¢¼ logique éŒ¯èª¤ (Code logic error)
        ('PASSED', 'Passed'),             # æ¸¬è©¦é€šé (Tests Passed)
    ]
    
    task = models.ForeignKey(EvaluationTask, on_delete=models.CASCADE, related_name='attempts')
    attempt_number = models.IntegerField()
    status = models.CharField(max_length=20, choices=STATUS_CHOICES)
    
    prompt_text = models.TextField(help_text="ç™¼é€çµ¦ LLM çš„å®Œæ•´æç¤º")
    raw_response = models.TextField(help_text="ä¾†è‡ª LLM çš„åŸå§‹å›æ‡‰")
    generated_patch = models.TextField(help_text="è©²æ¬¡å˜—è©¦ç”Ÿæˆçš„ git diff")
    test_output = models.TextField(help_text="Pytest çš„è¼¸å‡ºæ—¥èªŒ")
    
    timestamp = models.DateTimeField(auto_now_add=True)

    class Meta:
        ordering = ['attempt_number']

    def __str__(self):
        return f"Attempt {self.attempt_number} for {self.task.nocode_bench_id} - {self.status}"


class EvaluationResult(models.Model):
    task = models.OneToOneField(EvaluationTask, on_delete=models.CASCADE, related_name='result')
    
    # å¿…éœ€æŒ‡æ¨™ (Required Metrics)
    success_percent = models.FloatField(default=0.0)  # ğŸš€ æ›´æ”¹ï¼šæ–°åŠŸèƒ½æ¸¬è©¦ (F2P) æ˜¯å¦ 100% é€šé
                                                      # (CHANGE: Are new feature tests (F2P) 100% passed?)
    applied_percent = models.FloatField(default=0.0)
    rt_percent = models.FloatField(default=0.0)       # ğŸš€ æ›´æ”¹ï¼šè¿´æ­¸æ¸¬è©¦æ˜¯å¦ 100% é€šé
                                                      # (CHANGE: Are regression tests 100% passed?)
    
    # è«–æ–‡ä¸­çš„ FV-Macroï¼ˆæ¯å€‹å¯¦ä¾‹çš„ F2P é€šéç‡ï¼‰
    # (The paper's FV-Macro (per-instance F2P pass rate))
    fv_macro = models.FloatField(default=0.0)
    
    file_percent = models.FloatField(default=0.0)     # ğŸš€ æ›´æ”¹ï¼šé€™ç¾åœ¨æ˜¯ç²¾ç¢ºç‡ (Precision)
                                                      # (CHANGE: This is now Precision)
    num_token = models.IntegerField(default=0)
    
    # ğŸš€ æ–°å¢ï¼šè«–æ–‡ä¸­çš„å¯é¸æŒ‡æ¨™å’Œ FV è¨ˆç®—
    # (NEW: Optional metrics and FV calculation fields)
    run_time_seconds = models.FloatField(default=0.0) # é‹è¡Œæ™‚é–“ (Runtime)
    f2p_passed_count = models.IntegerField(default=0) # (ç”¨æ–¼ FV-Micro/Macro)
    f2p_total_count = models.IntegerField(default=0)  # (ç”¨æ–¼ FV-Micro/Macro)

    # è¼¸å‡º (Output)
    generated_patch = models.TextField(help_text="The code patch generated by the LLM.")

    # ğŸš€ ç§»é™¤ (REMOVED): èˆŠçš„ fv_microï¼Œå› ç‚ºå®ƒå¿…é ˆåœ¨å…¨å±€è¨ˆç®—
    # (Old fv_micro, as it must be calculated globally)