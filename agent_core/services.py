# agent_core/services.py
import os
import sys
import shutil
import subprocess
import time
import re
import stat
import platform
import json
from google import generativeai as genai
from google.generativeai.types import GenerationConfig
from django.conf import settings
from unidiff import PatchSet
from io import StringIO


# --- æ ¸å¿ƒè¨­å®š (Core Configuration) ---
ROOT_WORKSPACE = os.path.join(settings.BASE_DIR, 'nocode_workspaces')
os.makedirs(ROOT_WORKSPACE, exist_ok=True)
ORIGINAL_DATASET_ROOT = os.path.join(settings.BASE_DIR, 'NoCode-bench_Verified', 'data')


# --- æ¬Šé™éŒ¯èª¤è™•ç† (Permission Error Handler) ---
def onerror(func, path, exc_info):
    if not os.access(path, os.W_OK):
        os.chmod(path, stat.S_IWUSR | stat.S_IWRITE)
        func(path)
    else:
        raise

def _get_files_referencing_target(workspace_path: str, target_files: list[str], all_files: list[str]) -> list[str]:
    """
    ğŸš€ Agentless é¢¨æ ¼å„ªåŒ–ï¼š
    ç°¡å–®çš„å¼•ç”¨æœç´¢ã€‚å¦‚æœæˆ‘å€‘ä¿®æ”¹äº† 'utils.py'ï¼Œæˆ‘å€‘éœ€è¦æ‰¾åˆ°æ‰€æœ‰ import utils çš„æ–‡ä»¶ã€‚
    é€™æœƒé™ä½ File% (Precision)ï¼Œä½†æœƒå¤§å¹…æé«˜ RT% (Safety)ã€‚
    """
    expanded_files = set(target_files)
    
    # å»ºç«‹ä¸€å€‹ç°¡å–®çš„æ˜ å°„ï¼šæ–‡ä»¶å -> æ¨¡å¡Šå
    target_modules = []
    for f in target_files:
        filename = os.path.basename(f)
        name_no_ext = os.path.splitext(filename)[0]
        target_modules.append(name_no_ext)
    
    print(f"[Context Expansion] Searching for usages of: {target_modules}")

    for file_path in all_files:
        if file_path in expanded_files:
            continue
            
        full_path = os.path.join(workspace_path, file_path)
        try:
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                
            # ç°¡å–®çš„å•Ÿç™¼å¼æœç´¢ (Heuristic Search)
            for mod_name in target_modules:
                if (f"import {mod_name}" in content) or \
                   (f"from " in content and f"{mod_name}" in content) or \
                   (f"{mod_name}." in content):
                    expanded_files.add(file_path)
                    break
        except Exception:
            continue
            
    # é™åˆ¶æ“´å±•æ•¸é‡
    added_files = list(expanded_files - set(target_files))
    return list(expanded_files)


def _find_file_in_workspace(workspace_path: str, target_filename: str) -> str | None:
    """
    éæ­¸æœç´¢å·¥ä½œå€ä¸­çš„æª”æ¡ˆã€‚
    å¦‚æœæ‰¾åˆ°å”¯ä¸€çš„ä¸€å€‹åŒ¹é…é …ï¼Œè¿”å›å…¶ç›¸å°è·¯å¾‘ã€‚
    """
    matches = []
    ignore_dirs = {'.git', '.venv', 'venv', '__pycache__', 'site-packages'}
    
    for root, dirs, files in os.walk(workspace_path):
        dirs[:] = [d for d in dirs if d not in ignore_dirs]
        
        if target_filename in files:
            matches.append(os.path.join(root, target_filename))
    
    if len(matches) == 1:
        return os.path.relpath(matches[0], workspace_path).replace('\\', '/')
    
    if len(matches) > 1:
        print(f"WARNING: Found multiple matches for {target_filename}: {matches}. Skipping auto-fix.")
    
    return None

def _smart_fix_patch_paths(workspace_path: str, patch_str: str) -> str:
    """
    åˆ†æ Patchï¼Œå¦‚æœæª”æ¡ˆè·¯å¾‘ä¸å­˜åœ¨ï¼Œå˜—è©¦åœ¨å·¥ä½œå€ä¸­å°‹æ‰¾æ­£ç¢ºçš„è·¯å¾‘ä¸¦ä¿®æ­£ Patchã€‚
    """
    lines = patch_str.splitlines()
    path_map = {} 
    
    for line in lines:
        if line.startswith('--- ') or line.startswith('+++ '):
            raw_path = line[4:].strip()
            
            if raw_path == '/dev/null':
                continue
                
            clean_path = raw_path
            if raw_path.startswith('a/') or raw_path.startswith('b/'):
                clean_path = raw_path[2:]
            
            full_path = os.path.join(workspace_path, clean_path)
            
            if not os.path.exists(full_path) and clean_path not in path_map:
                filename = os.path.basename(clean_path)
                found_new_path = _find_file_in_workspace(workspace_path, filename)
                
                if found_new_path and found_new_path != clean_path:
                    print(f"[SmartPatch] Fixing path: {clean_path} -> {found_new_path}")
                    path_map[clean_path] = found_new_path

    if not path_map:
        return patch_str

    new_patch_str = patch_str
    for old_path, new_path in path_map.items():
        new_patch_str = new_patch_str.replace(f"a/{old_path}", f"a/{new_path}")
        new_patch_str = new_patch_str.replace(f"b/{old_path}", f"b/{new_path}")
        new_patch_str = new_patch_str.replace(f" {old_path}", f" {new_path}")
        new_patch_str = new_patch_str.replace(f"\t{old_path}", f"\t{new_path}")

    return new_patch_str
      
def _apply_patch(workspace_path: str, patch_str: str) -> tuple[bool, str | None]:
    """
    å°‡è£œä¸æ‡‰ç”¨åˆ° Git å€‰åº«ã€‚
    ğŸš€ å¢å¼·ç‰ˆ V3ï¼šåŒ…å«é‡è©¦æ©Ÿåˆ¶å’Œéƒ¨åˆ†æ‡‰ç”¨æ”¯æ´ã€‚
    """
    if not patch_str:
        return False, "Warning: Empty patch string provided."
    
    commands_to_try = [
        ['git', 'apply', '-p1', '--ignore-whitespace', '--verbose'],
        ['git', 'apply', '-p0', '--ignore-whitespace', '--verbose'],
        ['git', 'apply', '-p1', '-C1', '--ignore-whitespace', '--verbose'],
        ['git', 'apply', '-p1', '-3', '--ignore-whitespace', '--verbose'],
        ['git', 'apply', '-p1', '--reject', '--ignore-whitespace', '--verbose']
    ]

    # ğŸš€ éšæ®µ 1: ç›´æ¥å˜—è©¦
    success, msg = _try_apply_commands(workspace_path, patch_str, commands_to_try)
    if success:
        return True, None

    # ğŸš€ éšæ®µ 2: æ™ºæ…§è·¯å¾‘ä¿®æ­£å¾Œå˜—è©¦
    print("Direct patch apply failed. Attempting Smart Path Correction...")
    fixed_patch_str = _smart_fix_patch_paths(workspace_path, patch_str)
    
    if fixed_patch_str != patch_str:
        success, msg = _try_apply_commands(workspace_path, fixed_patch_str, commands_to_try)
        if success:
            print("Smart Path Correction successful!")
            return True, None
    else:
        print("Smart Path Correction found no paths to fix.")

    return False, f"Failed to apply patch after Smart Fix.\nLast Error: {msg}"

def _try_apply_commands(workspace_path, patch_str, commands):
    """
    å˜—è©¦ä¸€ç³»åˆ— git apply å‘½ä»¤ã€‚åŒ…å«æ¸…ç†æ©Ÿåˆ¶ã€‚
    """
    last_error = ""
    patch_file_path = os.path.join(workspace_path, "temp_apply_patch.diff")
    
    try:
        with open(patch_file_path, 'w', encoding='utf-8', newline='\n') as f:
            f.write(patch_str)
            if not patch_str.endswith('\n'):
                f.write('\n')

        for cmd in commands:
            full_cmd = cmd + [patch_file_path]
            try:
                result = subprocess.run(
                    full_cmd, cwd=workspace_path, text=True, check=False,
                    capture_output=True, encoding='utf-8', errors='replace'
                )
                
                if result.returncode == 0:
                    return True, None
                
                stderr_output = result.stderr
                stdout_output = result.stdout
                combined_output = (stderr_output + stdout_output).lower()

                if "already exists in working directory" in combined_output:
                    print(f"WARNING: File already exists. Assuming setup is okay. (Cmd: {cmd})")
                    return True, None

                if '--reject' in cmd and ("rejected hunk" in combined_output or "applied patch" in combined_output):
                    print(f"WARNING: Partial apply with --reject. Continuing.\nDetails: {stderr_output[:200]}...")
                    return True, None

                last_error = stderr_output
                
                # ğŸš€ é—œéµä¿®å¾©: æ¸…ç†æˆ°å ´ï¼Œé˜²æ­¢ç•™ä¸‹ <<<<<<< ours
                subprocess.run(['git', 'checkout', '.'], cwd=workspace_path, check=False, capture_output=True)

            except Exception as e:
                last_error = str(e)
                subprocess.run(['git', 'checkout', '.'], cwd=workspace_path, check=False, capture_output=True)

    finally:
        if os.path.exists(patch_file_path):
            try: os.remove(patch_file_path)
            except: pass
            
    return False, last_error


# --- è¼”åŠ©å‡½æ•¸ (Helper Functions) ---

def setup_workspace(nocode_bench_id: str) -> str:
    parts = nocode_bench_id.split('__')
    repo_owner = parts[0]
    match = re.match(r'^(.*?)-(\d+)$', parts[1])
    if match:
        repo_name_base = match.group(1) 
    else:
        repo_name_base = parts[1].split('-')[0]
    repo_path_segment = os.path.join(repo_owner, repo_name_base)
    original_repo_path = os.path.join(ORIGINAL_DATASET_ROOT, repo_path_segment)
    run_id = str(time.time()).replace('.', '')
    temp_dir = os.path.join(ROOT_WORKSPACE, f'run_{nocode_bench_id.replace("__", "_")}_{run_id}')
    
    if not os.path.exists(original_repo_path):
        raise FileNotFoundError(f"Original codebase not found! Check path: {original_repo_path}")
    
    try:
        shutil.copytree(original_repo_path, temp_dir)
        subprocess.run(['git', 'init'], cwd=temp_dir, check=True, capture_output=True, text=True, encoding='utf-8')
        # ğŸš€ é—œéµä¿®å¾©: é—œé–‰è‡ªå‹• CRLF
        subprocess.run(['git', 'config', 'core.autocrlf', 'false'], cwd=temp_dir, check=True)
        subprocess.run(['git', 'add', '.'], cwd=temp_dir, check=True, capture_output=True, text=True, encoding='utf-8')
        subprocess.run(['git', 'commit', '-m', 'Initial snapshot', '--allow-empty'], cwd=temp_dir, check=True, capture_output=True, text=True, encoding='utf-8')
        return temp_dir
    except subprocess.CalledProcessError as e:
        raise IOError(f"Failed to initialize Git: {e.stderr}")
    except Exception as e:
        raise IOError(f"File operation failed: {e}")


def _run_tests_in_workspace(
    workspace_path: str, 
    feature_test_patch: str, 
    f2p_test_names: list[str], 
    p2p_test_names: list[str]
) -> tuple[int, int, int, int, str]:
    """
    é‹è¡Œæ¸¬è©¦çš„å®Œæ•´æµç¨‹å‡½æ•¸ (Full Pipeline)ã€‚
    åŒ…å«ï¼šå»ºç«‹ Venv -> å®‰è£ä¾è³´ -> æ‡‰ç”¨ Patch -> èªæ³•æª¢æŸ¥ -> æ™ºæ…§ç¯©é¸æ¸¬è©¦ -> åŸ·è¡Œ Pytest -> è§£æå ±å‘Šã€‚
    """
    venv_path = os.path.join(workspace_path, 'venv')
    
    # æ±ºå®š Python åŸ·è¡Œæª”è·¯å¾‘
    if platform.system() == "Windows":
        python_executable = os.path.join(venv_path, 'Scripts', 'python.exe')
        pip_executable = os.path.join(venv_path, 'Scripts', 'pip.exe')
    else:
        python_executable = os.path.join(venv_path, 'bin', 'python')
        pip_executable = os.path.join(venv_path, 'bin', 'pip')

    full_log = []
    
    # åˆå§‹åŒ–è¨ˆæ•¸å™¨
    f2p_passed_count = 0
    f2p_total_count = len(f2p_test_names)
    p2p_passed_count = 0
    p2p_total_count = len(p2p_test_names)
    
    try:
        # =========================================================================
        # æ­¥é©Ÿ 1: å»ºç«‹è™›æ“¬ç’°å¢ƒ (Create Venv) - é€™æ˜¯ WinError 2 çš„è§£è—¥
        # =========================================================================
        print("Creating venv...")
        # ä½¿ç”¨ç•¶å‰ç³»çµ±çš„ Python ä¾†å‰µå»º venv
        sys_python = sys.executable 
        venv_created = False
        log_stderr = ""
        
        try:
            # ç¢ºä¿ venv ç›®éŒ„ä¸å­˜åœ¨ (ä¹¾æ·¨å®‰è£)
            if os.path.exists(venv_path):
                shutil.rmtree(venv_path)
                
            result = subprocess.run(
                [sys_python, '-m', 'venv', venv_path], 
                cwd=workspace_path, capture_output=True, check=True,
                text=True, encoding='utf-8', errors='replace'
            )
            venv_created = True
            print(f"Venv created at: {venv_path}")
        except (subprocess.CalledProcessError, FileNotFoundError) as e:
            log_stderr = str(e)
            full_log.append(f"Failed to create venv: {log_stderr}")
        
        # é›™é‡æª¢æŸ¥ python.exe æ˜¯å¦çœŸçš„å­˜åœ¨
        if not venv_created or not os.path.exists(python_executable):
            return 0, f2p_total_count, 0, p2p_total_count, f"FATAL: python.exe not found at {python_executable}. Venv creation failed."

        # =========================================================================
        # æ­¥é©Ÿ 2: å®‰è£ä¾è³´ (Install Dependencies)
        # =========================================================================
        print("Installing base test dependencies...")
        deps_to_install = ['pytest', 'trustme', 'pytest-json-report', 'setuptools', 'pytest-django', 'pytest-timeout']
        
        # å‡ç´š pip (å¯é¸ï¼Œä½†æ¨è–¦)
        subprocess.run([python_executable, '-m', 'pip', 'install', '--upgrade', 'pip'], cwd=workspace_path, capture_output=True)
        
        install_cmd = [pip_executable, 'install'] + deps_to_install
        result = subprocess.run(install_cmd, cwd=workspace_path, capture_output=True, check=False)
        full_log.append(f"--- Dependencies (Base) ---\n{result.stdout.decode('utf-8', errors='replace')}")
        
        if result.returncode != 0:
            return 0, f2p_total_count, 0, p2p_total_count, f"Failed to install dependencies.\n{full_log[-1]}"

        # å®‰è£å°ˆæ¡ˆç‰¹å®šçš„ requirements
        print("Searching for project-specific requirements...")
        dev_req_files_set = {'requirements.txt', 'requirements-dev.txt', 'requirements_test.txt', 'test-requirements.txt', 'dev-requirements.txt'}
        found_dev_req = False
        for root, dirs, files in os.walk(workspace_path):
            if 'venv' in dirs: dirs.remove('venv')
            if '.git' in dirs: dirs.remove('.git')
            
            for file_name in files:
                if file_name in dev_req_files_set:
                    req_path = os.path.join(root, file_name)
                    print(f"Installing {file_name}...")
                    subprocess.run([pip_executable, 'install', '-r', req_path], cwd=workspace_path, capture_output=True, check=False)
                    found_dev_req = True
                    break # åªå®‰è£æ‰¾åˆ°çš„ç¬¬ä¸€å€‹ä¸»è¦ä¾è³´æª”ï¼Œé¿å…è¡çª
            if found_dev_req: break
        
        # å®‰è£å°ˆæ¡ˆæœ¬èº« (Editable mode)
        if os.path.exists(os.path.join(workspace_path, 'setup.py')) or os.path.exists(os.path.join(workspace_path, 'pyproject.toml')):
            print("Installing project in editable mode...")
            subprocess.run([pip_executable, 'install', '-e', '.'], cwd=workspace_path, capture_output=True, check=False)

        # =========================================================================
        # æ­¥é©Ÿ 3: æ‡‰ç”¨è£œä¸ (Apply Patch)
        # =========================================================================
        print(f"Applying ground-truth test patch...")
        success, error_msg = _apply_patch(workspace_path, feature_test_patch)
        if not success:
             return 0, f2p_total_count, 0, p2p_total_count, f"FATAL: Failed to apply test patch.\n{error_msg}"
        
        # =========================================================================
        # æ­¥é©Ÿ 4: èªæ³•æª¢æŸ¥ (Syntax Check)
        # =========================================================================
        print("Running syntax check...")
        syntax_error_found = False
        syntax_error_details = ""
        IGNORE_DIRS = {'.git', '.venv', 'venv', '__pycache__', 'doc', 'docs', 'test_runner_apps', 'invalid_models', 'broken_app'}
        SKIP_KEYWORDS = ['/data', '/input', '/messages', '/functional', '/invalid', '/bad_code', '/syntax_error']

        for root, dirs, files in os.walk(workspace_path):
            dirs[:] = [d for d in dirs if d not in IGNORE_DIRS]
            rel_root = os.path.relpath(root, workspace_path).replace('\\', '/')
            if any(k in rel_root for k in SKIP_KEYWORDS): continue

            for file in files:
                if file.endswith('.py'):
                    if 'syntax_error' in file or 'invalid' in file: continue
                    full_path = os.path.join(root, file)
                    try:
                        subprocess.run([python_executable, '-m', 'py_compile', full_path], check=True, capture_output=True)
                    except subprocess.CalledProcessError as e:
                        if any(k in full_path.replace('\\', '/') for k in SKIP_KEYWORDS): continue
                        syntax_error_details = f"SyntaxError in {file}: {e.stderr}"
                        syntax_error_found = True
                        break
            if syntax_error_found: break

        if syntax_error_found:
            return 0, f2p_total_count, 0, p2p_total_count, f"--- Syntax Check Failed ---\n{syntax_error_details}"

        # =========================================================================
        # æ­¥é©Ÿ 5: é‹è¡Œæ¸¬è©¦ (Run Tests)
        # =========================================================================
        print(f"Preparing to run tests...")
        report_file = os.path.join(workspace_path, 'combined_report.json')
        
        # A. å»ºç«‹æª”æ¡ˆæ˜ å°„ (Inventory Map)
        # Key: "path/to/module" (ç„¡å‰¯æª”å), Value: "C:/Abs/Path/to/module.py"
        inventory_map = {}
        scan_root = os.path.join(workspace_path, 'tests') if os.path.exists(os.path.join(workspace_path, 'tests')) else workspace_path
        
        EXCLUDE_FILES = {'runtests.py', 'conftest.py', 'setup.py', '__init__.py'}
        
        for root, dirs, files in os.walk(scan_root):
            if 'venv' in dirs: dirs.remove('venv')
            if '.git' in dirs: dirs.remove('.git')
            
            for file in files:
                if file.endswith('.py') and file not in EXCLUDE_FILES:
                    full_path = os.path.join(root, file)
                    rel_path = os.path.relpath(full_path, workspace_path).replace('\\', '/')
                    # ç§»é™¤ .py
                    path_no_ext = rel_path[:-3] 
                    
                    # å„²å­˜å®Œæ•´æ˜ å°„
                    inventory_map[path_no_ext] = full_path
                    
                    # é‡å° Djangoï¼Œå¦‚æœæ˜¯ "tests/admin/..." ä¹Ÿå„²å­˜ä¸€ä»½ "admin/..."
                    if path_no_ext.startswith("tests/"):
                        inventory_map[path_no_ext[6:]] = full_path

        # B. åŒ¹é…ç›®æ¨™æ¸¬è©¦ (éæ¸›æœå°‹)
        target_files_abs = set()
        all_target_tests = set(f2p_test_names) | set(p2p_test_names)
        
        print(f"Resolving {len(all_target_tests)} tests against {len(inventory_map)} files...")

        for test_id in all_target_tests:
            if not test_id: continue
            
            # ğŸš€ é—œéµä¿®å¾©ï¼šåŒæ™‚è™•ç† . å’Œ \ (Handle both dots and backslashes)
            # ç¢ºä¿ "tests\admin\test_x" å’Œ "tests.admin.test_x" éƒ½èƒ½è¢«è½‰ç‚º "tests/admin/test_x"
            clean_id = test_id.split('[')[0]
            clean_id = clean_id.replace('\\', '/').replace('.', '/')
            
            parts = clean_id.split('/')
            
            found = False
            # ç­–ç•¥ 1: éæ¸›è·¯å¾‘åŒ¹é… (Decremental Path Matching)
            # å¾æœ€é•·è·¯å¾‘é–‹å§‹å˜—è©¦: "tests/admin/test_file/Class/method" -> "tests/admin/test_file"
            for i in range(len(parts), 0, -1):
                candidate_key = "/".join(parts[:i])
                if candidate_key in inventory_map:
                    target_files_abs.add(inventory_map[candidate_key])
                    found = True
                    break
            
            # ç­–ç•¥ 2: æª”åå¾Œç¶´åŒ¹é… (Filename Suffix Fallback)
            if not found:
                # å–å€’æ•¸ç¬¬äºŒå€‹éƒ¨åˆ† (é€šå¸¸æ˜¯æª”å)
                # ä¾‹å¦‚ "tests/admin/test_something/TestClass" -> æ‰¾ "test_something.py"
                candidate_name = parts[-2] if len(parts) > 1 else parts[0]
                
                # å¦‚æœè©²åç¨±çœ‹èµ·ä¾†åƒæ¸¬è©¦æª” (ä»¥ test é–‹é ­æˆ– tests çµå°¾)ï¼Œå˜—è©¦æœå°‹
                for key, path in inventory_map.items():
                    # æª¢æŸ¥ key çš„çµå°¾æ˜¯å¦åŒ¹é… (e.g. key="admin/test_something", candidate="test_something")
                    if key.endswith("/" + candidate_name) or key == candidate_name:
                        target_files_abs.add(path)
                        found = True
                        break

        target_files_list = sorted(list(target_files_abs))
        
        tests_args = []
        if not target_files_list:
            print("WARNING: No files matched. Falling back to 'tests/' directory.")
            if os.path.exists(os.path.join(workspace_path, 'tests')):
                tests_args = [os.path.join(workspace_path, 'tests')]
        else:
            print(f"ğŸš€ Identified {len(target_files_list)} relevant files for execution.")
            tests_args = target_files_list

        # C. æ³¨å…¥ Conftest (å« skip_dirs)
        is_django_repo = os.path.exists(os.path.join(workspace_path, 'django')) and \
                         os.path.exists(os.path.join(workspace_path, 'tests', 'runtests.py'))
        if is_django_repo:
            conftest_path = os.path.join(workspace_path, 'conftest.py')
            with open(conftest_path, 'w', encoding='utf-8') as f:
                f.write("""
import os
import sys
from django.conf import settings

def discover_test_apps():
    apps = []
    tests_dir = os.path.join(os.getcwd(), "tests")
    skip = {'import_error_package', 'test_runner_apps', 'check_framework', 'admin_scripts', 'bash_completion', '__pycache__', 'admin_autodiscover', 'admin_default_site', 'broken_app', 'invalid_models_tests', 'gis_tests', 'postgres_tests'}
    if os.path.exists(tests_dir):
        for item in os.listdir(tests_dir):
            if item in skip or item.startswith('.'): continue
            full_path = os.path.join(tests_dir, item)
            if os.path.isdir(full_path) and os.path.exists(os.path.join(full_path, "__init__.py")):
                apps.append(item)
    return apps

def pytest_configure(config):
    sys.path.insert(0, os.path.join(os.getcwd(), "tests"))
    if not settings.configured:
        settings.configure(
            DEBUG=False,
            DATABASES={'default': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': ':memory:'}, 'other': {'ENGINE': 'django.db.backends.sqlite3', 'NAME': ':memory:'}},
            INSTALLED_APPS=['django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'django.contrib.sites', 'django.contrib.flatpages', 'django.contrib.redirects', 'django.contrib.sitemaps', 'django.contrib.humanize', 'django.contrib.admindocs'] + discover_test_apps(),
            SITE_ID=1, SECRET_KEY='test-key', ROOT_URLCONF='', USE_TZ=True,
            MIDDLEWARE=['django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware'],
            TEMPLATES=[{'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [], 'APP_DIRS': True, 'OPTIONS': {'context_processors': ['django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages']}}],
            MIGRATION_MODULES={'auth': None, 'contenttypes': None, 'sessions': None, 'admin': None},
        )
""")

        # D. åŸ·è¡Œ Pytest
        clean_env = os.environ.copy()
        if 'DJANGO_SETTINGS_MODULE' in clean_env: del clean_env['DJANGO_SETTINGS_MODULE']
        clean_env['PYTHONPATH'] = workspace_path + os.pathsep + clean_env.get('PYTHONPATH', '')
        clean_env['PYTHONUNBUFFERED'] = '1'

        pytest_cmd = [
            python_executable, '-m', 'pytest', 
            '--json-report', f'--json-report-file={report_file}',
            '--continue-on-collection-errors',
            '--timeout=30',
            '-v'
        ] + tests_args

        stdout_file = os.path.join(workspace_path, 'pytest_stdout.txt')
        stderr_file = os.path.join(workspace_path, 'pytest_stderr.txt')
        
        try:
            with open(stdout_file, 'w', encoding='utf-8') as fout, open(stderr_file, 'w', encoding='utf-8') as ferr:
                print(f"Starting pytest (Running {len(target_files_list) if target_files_list else 'ALL'} files)...")
                subprocess.run(pytest_cmd, cwd=workspace_path, check=False, timeout=3600, env=clean_env, stdout=fout, stderr=ferr)
            
            with open(stdout_file, 'r', encoding='utf-8', errors='replace') as f: log_stdout = f.read()
            with open(stderr_file, 'r', encoding='utf-8', errors='replace') as f: log_stderr = f.read()
            full_log.append(f"--- Pytest Output ---\n{log_stdout}\n{log_stderr}")
            
        except subprocess.TimeoutExpired:
            full_log.append("--- Pytest Timeout (1h) ---")

        # --- æ­¥é©Ÿ 6ï¼šè§£æçµæœ (ID æ¨™æº–åŒ–) ---
        try:
            if os.path.exists(report_file):
                with open(report_file, 'r') as f:
                    report = json.load(f)
                
                def normalize(tid):
                    return tid.replace('.py', '').replace('/', '.').replace('\\', '.').replace('::', '.')

                f2p_norm = {normalize(n) for n in f2p_test_names}
                p2p_norm = {normalize(n) for n in p2p_test_names}
                
                if 'tests' in report:
                    for test in report['tests']:
                        if test.get('outcome') == 'passed':
                            nid = normalize(test.get('nodeid', ''))
                            if nid in f2p_norm: f2p_passed_count += 1
                            elif nid in p2p_norm: p2p_passed_count += 1
                            else:
                                for f in f2p_norm:
                                    if nid.endswith(f) or f.endswith(nid): f2p_passed_count += 1; break
                                for p in p2p_norm:
                                    if nid.endswith(p) or p.endswith(nid): p2p_passed_count += 1; break
            
            print(f"Results -> F2P: {f2p_passed_count}/{f2p_total_count}, P2P: {p2p_passed_count}/{p2p_total_count}")
            
        except Exception as e:
            full_log.append(f"Report parsing error: {e}")

        return f2p_passed_count, f2p_total_count, p2p_passed_count, p2p_total_count, "\n".join(full_log)

    except Exception as e:
        return 0, f2p_total_count, 0, p2p_total_count, f"Unexpected Error: {e}"
    
def _get_relevant_files_from_llm(model, doc_change: str, workspace_path: str) -> list[str]:
    """
    (æ­¤å‡½æ•¸ä¿æŒä¸è®Š)
    """
    all_files = []
    for root, _, files in os.walk(workspace_path):
        if '.git' in root or 'docs' in root or '.venv' in root or 'venv' in root: continue
        for file in files:
            if file.endswith(('.py', '.html', '.css', '.js', 'setup.py', 'requirements.txt')):
                rel_path = os.path.relpath(os.path.join(root, file), workspace_path)
                all_files.append(rel_path.replace('\\', '/'))

    # ... (LLM æç¤ºè© Prompt éƒ¨åˆ†ï¼Œç¨å¾®ä¿®æ”¹æç¤ºè©ä»¥å¼·èª¿å°‹æ‰¾ä¾è³´) ...
    
    prompt = (
        f"You are a tech lead. Identify the files needed to implement this documentation change.\n"
        f"**DOC CHANGE:**\n{doc_change}\n\n"
        f"**FILES:**\n{', '.join(all_files)}\n\n"
        f"**INSTRUCTIONS:**\n"
        "1. Identify the CORE files that need modification.\n"
        "2. Think: If I modify these core files, which other files import them?\n" # å¼·èª¿æ€è€ƒå¼•ç”¨
        "3. Return JSON: {{\"files\": [\"path/to/core.py\"]}}\n"
    )

    response_text = None
    try:
        response = model.generate_content(
            prompt,
            generation_config=GenerationConfig(
                response_mime_type="application/json"
            )
        )
        # (å‡½æ•¸çš„å…¶é¤˜éƒ¨åˆ†ä¿æŒä¸è®Š)
        response_text = response.text
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if not json_match:
            print(f"[Task] ERROR: AI response did not contain a JSON object. Response: {response_text}")
            return []
        json_text = json_match.group(0)
        print(f"[Task] DEBUG: File finder LLM response (extracted):\n{json_text}")
        data = json.loads(json_text)
        if "files" not in data or not isinstance(data["files"], list):
            print(f"[Task] ERROR: AI response JSON was in wrong format: {json_text}")
            return []
        llm_files = data["files"]
        valid_files = [f.strip().replace('\\', '/') for f in llm_files if f.strip() in all_files]

        if valid_files:
            print(f"[Task] LLM identified core files: {valid_files}")
            # æ“´å±•ä¸Šä¸‹æ–‡ï¼šæ‰¾å‡ºèª°ç”¨äº†é€™äº›æ–‡ä»¶
            expanded_list = _get_files_referencing_target(workspace_path, valid_files, all_files)
            
            # å¦‚æœæ“´å±•å¤ªå¤šï¼Œæˆ‘å€‘å¯ä»¥æˆªæ–·ï¼Œæˆ–è€…åªå–å‰ N å€‹
            if len(expanded_list) > 10: 
                print(f"[Task] Expanding context limited to top 10 extra files.")
                # ç¢ºä¿åŸå§‹æ–‡ä»¶åœ¨è£¡é¢ï¼Œç„¶å¾Œè£œä¸Šå‰å¹¾å€‹å¼•ç”¨è€…
                extras = [f for f in expanded_list if f not in valid_files][:10]
                valid_files = valid_files + extras
            else:
                valid_files = expanded_list
                
            print(f"[Task] Final file list (including dependants): {valid_files}")
            
        return valid_files
    except json.JSONDecodeError:
        print(f"[Task] ERROR: AI response was not valid JSON: {response_text}")
        return []
    except Exception as e:
        print(f"[Task] ERROR: Failed to parse AI file list: {e}\nResponse text: {response_text}")
        return []

def _get_file_contexts(workspace_path: str, relevant_files: list[str]) -> str:
    """
    (æ­¤å‡½æ•¸ä¿æŒä¸è®Š)
    (This function is unchanged)
    """
    context_prompt_parts = []
    # ... (æ­¤å‡½æ•¸çš„å…¶é¤˜éƒ¨åˆ†ä¿æŒä¸è®Š) ...
    for file_path in relevant_files:
        full_path = os.path.join(workspace_path, file_path)
        if not os.path.exists(full_path):
            print(f"WARNING: File `{file_path}` identified by AI does not exist. Skipping.")
            continue
        try:
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                file_content = f.read()
            context_prompt_parts.append(
                f"--- START OF FILE: {file_path} ---\n"
                f"{file_content}\n"
                f"--- END OF FILE: {file_path} ---\n"
            )
        except Exception as e:
            print(f"Error reading file {file_path}: {e}")
    return "\n".join(context_prompt_parts)

def _parse_v7_response(raw_response_text: str) -> dict[str, str]:
    """
    (æ­¤å‡½æ•¸ä¿æŒä¸è®Š)
    (This function is unchanged)
    """
    modified_files = {}
    # ... (æ­¤å‡½æ•¸çš„å…¶é¤˜éƒ¨åˆ†ä¿æŒä¸è®Š) ...
    file_chunks = re.split(r'--- START OF FILE: (.*?) ---\n', raw_response_text)
    if len(file_chunks) < 2:
        raise ValueError("AI response did not contain any '--- START OF FILE: ' delimiters.")
    for i in range(1, len(file_chunks), 2):
        file_path = file_chunks[i].strip()
        content_part = file_chunks[i+1]
        content = re.sub(r'--- END OF FILE: .*? ---', '', content_part, flags=re.DOTALL).strip()
        if file_path and content:
            modified_files[file_path] = content
        else:
            print(f"WARNING: Could not parse file chunk: Filepath='{file_path}', Content preview='{content[:50]}...'")
    if not modified_files:
        raise ValueError("AI response was parsed, but no valid file content blocks were found.")
    return modified_files


# --- æŒ‡æ¨™è¨ˆç®— (Metrics Calculation) ---
# (parse_patch å’Œ calculate_f1_score ä¿æŒä¸è®Š)
def parse_patch(patch_str: str) -> dict[str, set[int]]:
    if not patch_str: return {}
    try:
        patch = PatchSet(StringIO(patch_str))
        changed_files = {}
        for patched_file in patch:
            if patched_file.is_binary_file: continue
            file_path = patched_file.target_file[2:] if patched_file.target_file.startswith('b/') else patched_file.target_file
            changed_lines = set()
            for hunk in patched_file:
                for line in hunk:
                    if line.is_added:
                        changed_lines.add(line.target_line_no)
                    elif line.is_removed:
                        changed_lines.add(line.source_line_no)
            if changed_lines:
                changed_files[file_path] = changed_lines
        return changed_files
    except Exception as e:
        print(f"Error parsing patch: {e}\nPatch content:\n{patch_str[:500]}...")
        return {}

def calculate_f1_score(pred_set: set, gold_set: set) -> float:
    if not gold_set: return 1.0 if not pred_set else 0.0
    if not pred_set: return 0.0
    tp = len(pred_set.intersection(gold_set))
    fp = len(pred_set.difference(gold_set))
    fn = len(gold_set.difference(pred_set))
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    return f1

def calculate_all_metrics(
    f2p_passed_count: int,
    f2p_total_count: int,
    p2p_passed_count: int,
    p2p_total_count: int,
    regression_tests_passed: bool,
    applied_successfully: bool, 
    generated_patch: str, 
    ground_truth_patch: str, 
    run_time_seconds: float
) -> dict:
    """
    è¨ˆç®—æŒ‡æ¨™ã€‚Success% å’Œ RT% éƒ½æ¡ç”¨çœŸå¯¦æ¯”ç‡ (Ratio)ã€‚
    """
    
    # 1. Success% (æ–°åŠŸèƒ½æ¸¬è©¦é€šéç‡)
    if f2p_total_count > 0:
        success_percent = (f2p_passed_count / f2p_total_count) * 100.0
    else:
        success_percent = 0.0 

    applied_percent = 100.0 if applied_successfully else 0.0
    
    # 2. RT% (è¿´æ­¸æ¸¬è©¦é€šéç‡)
    # ğŸš€ ç¢ºä¿é€™æ˜¯çœŸå¯¦çš„æ¯”ç‡ (Actual Ratio)ï¼Œè€Œä¸æ˜¯ 100/0
    if p2p_total_count > 0:
        rt_percent = (p2p_passed_count / p2p_total_count) * 100.0
    else:
        # å¦‚æœæ²’æœ‰è¿´æ­¸æ¸¬è©¦ï¼Œé€šå¸¸é»˜èªç‚º 100% (æ²’æœ‰ç ´å£ä»»ä½•æ±è¥¿)
        rt_percent = 100.0
    
    # FV-Macro
    fv_macro = success_percent # åŒ Success%

    # File%
    pred_files_lines = parse_patch(generated_patch)
    gold_files_lines = parse_patch(ground_truth_patch)
    pred_file_set = set(pred_files_lines.keys())
    gold_file_set = set(gold_files_lines.keys())
    
    file_intersection = len(pred_file_set.intersection(gold_file_set))
    if len(pred_file_set) == 0:
        file_percent = 100.0 if len(gold_file_set) == 0 else 0.0
    else:
        file_percent = (file_intersection / len(pred_file_set)) * 100.0

    return {
        'success_percent': round(success_percent, 2),
        'applied_percent': applied_percent,
        'rt_percent': round(rt_percent, 2), # é€™è£¡æœƒé¡¯ç¤ºä¾‹å¦‚ 95.5
        'fv_macro': fv_macro,
        'file_percent': file_percent,
        'num_token': len(generated_patch.split()),
        'run_time_seconds': run_time_seconds,
        'f2p_passed_count': f2p_passed_count,
        'f2p_total_count': f2p_total_count,
        'p2p_passed_count': p2p_passed_count,
        'p2p_total_count': p2p_total_count,
    }

# --- æ ¸å¿ƒ Agent å·¥ä½œå‡½æ•¸ (Core Agent Worker Function) ---

def run_agent_attempt(
    workspace_path: str, 
    model, 
    prompt_text: str, 
    feature_test_patch: str,
    f2p_test_names: list[str],
    p2p_test_names: list[str]
) -> dict:
    """
    åŸ·è¡Œä¸€æ¬¡ Agent å˜—è©¦ï¼šç”Ÿæˆä»£ç¢¼ -> æ‡‰ç”¨ -> æ¸¬è©¦ã€‚
    (Executes one Agent attempt: Generate Code -> Apply -> Test.)
    
    ğŸš€ é‡å¤§ä¿®æ”¹ (MAJOR CHANGE): 
    ç¾åœ¨å¯¦æ–½ã€Œåš´æ ¼é€šéæ¨™æº–ã€(Strict Passing Criteria)ã€‚
    åªæœ‰ç•¶ F2P (æ–°åŠŸèƒ½) å’Œ P2P (èˆŠåŠŸèƒ½) å…¨éƒ¨é€šéæ™‚ï¼Œæ‰è¦–ç‚ºæˆåŠŸã€‚
    (Now enforces Strict Passing Criteria. Only considered successful if BOTH F2P and P2P pass.)
    """
    
    raw_response_text = ""
    final_patch_str = ""
    test_output = ""
    
    try:
        # é‡ç½®å·¥ä½œå€ (Reset workspace)
        subprocess.run(['git', 'reset', '--hard', 'HEAD'], cwd=workspace_path, capture_output=True, text=True, check=True)
        
        # 1. ç”Ÿæˆç¨‹å¼ç¢¼ (Generate Code)
        response = model.generate_content(prompt_text)
        raw_response_text = response.text
        
        # 2. è§£æå›æ‡‰ (Parse Response)
        try:
            modified_files = _parse_v7_response(raw_response_text)
        except Exception as e:
            print(f"ERROR: AI response parsing failed: {e}\nRaw Response: {raw_response_text[:1000]}")
            return {
                'status': 'APPLY_FAILED', 'error': f"AI response parsing failed: {e}",
                'patch': '', 'raw_response': raw_response_text,
                'f2p_passed_count': 0, 'f2p_total_count': 0, 
                'p2p_passed_count': 0, 'p2p_total_count': 0,
                'regression_tests_passed': False
            }

        # 3. å°‡æ–°å…§å®¹å¯«å…¥æ–‡ä»¶ (Write new contents to files)
        for file_path, new_content in modified_files.items():
            try:
                if '..' in file_path: continue
                full_path = os.path.join(workspace_path, file_path)
                os.makedirs(os.path.dirname(full_path), exist_ok=True)
                with open(full_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
            except Exception as e:
                 return {
                    'status': 'APPLY_FAILED', 'error': f"Failed to write file {file_path} to disk: {e}",
                    'patch': '', 'raw_response': raw_response_text,
                    'f2p_passed_count': 0, 'f2p_total_count': 0, 
                    'p2p_passed_count': 0, 'p2p_total_count': 0,
                    'regression_tests_passed': False
                }

        # 4. ç”Ÿæˆè£œä¸ (Generate Patch)
        diff_result = subprocess.run(
            ['git', 'diff', '--no-prefix'], 
            cwd=workspace_path, capture_output=True, text=True, check=True, encoding='utf-8'
        )
        final_patch_str = diff_result.stdout
        
        if not final_patch_str:
             return {
                'status': 'TEST_FAILED', 'patch': '',
                'test_output': 'AI agent produced no code changes.',
                'raw_response': raw_response_text,
                'f2p_passed_count': 0, 'f2p_total_count': 0,
                'p2p_passed_count': 0, 'p2p_total_count': 0,
                'regression_tests_passed': False,
            }

        # 5. é‹è¡Œçµ„åˆæ¸¬è©¦ä¸¦æ•ç² 4 å€‹è¨ˆæ•¸å™¨ (Run combined tests and capture 4 counters)
        f2p_passed_count, f2p_total_count, p2p_passed_count, p2p_total_count, test_output = _run_tests_in_workspace(
            workspace_path, 
            feature_test_patch,
            f2p_test_names,
            p2p_test_names
        )
        
        # --- ğŸš€ é—œéµä¿®æ”¹é‚è¼¯ (CRITICAL MODIFIED LOGIC) ---
        
        # åˆ¤æ–· F2P æ˜¯å¦å…¨é (Check if all Feature tests passed)
        feature_tests_passed = (f2p_passed_count == f2p_total_count) if f2p_total_count > 0 else False
        
        # åˆ¤æ–· P2P æ˜¯å¦å…¨é (Check if all Regression tests passed)
        # å¦‚æœæ²’æœ‰ P2P æ¸¬è©¦ (count=0)ï¼Œé è¨­è¦–ç‚ºé€šé
        regression_tests_passed = (p2p_passed_count == p2p_total_count) if p2p_total_count > 0 else True
        
        if feature_tests_passed:
            status = 'PASSED'
        else:
            status = 'TEST_FAILED' 

        return {
            'status': status, 
            'patch': final_patch_str,
            'test_output': test_output, 
            'raw_response': raw_response_text,
            'f2p_passed_count': f2p_passed_count,
            'f2p_total_count': f2p_total_count,
            'p2p_passed_count': p2p_passed_count,
            'p2p_total_count': p2p_total_count,
            'regression_tests_passed': regression_tests_passed,
        }
        
    except Exception as e:
        print(f"FATAL ERROR in run_agent_attempt: {e}")
        return {
            'status': 'APPLY_FAILED',
            'error': f"An unexpected error occurred in the agent worker: {e}",
            'patch': final_patch_str,
            'test_output': test_output,
            'raw_response': raw_response_text,
            'f2p_passed_count': 0, 'f2p_total_count': 0, 
            'p2p_passed_count': 0, 'p2p_total_count': 0,
            'regression_tests_passed': False
        }

def setup_custom_workspace(github_url: str) -> str:
    """
    (æ­¤å‡½æ•¸ä¿æŒä¸è®Š)
    """
    run_id = str(time.time()).replace('.', '')
    # ç”¢ç”Ÿä¸€å€‹å”¯ä¸€çš„ç›®éŒ„åç¨±
    repo_name = github_url.split('/')[-1].replace('.git', '')
    temp_dir = os.path.join(ROOT_WORKSPACE, f'demo_{repo_name}_{run_id}')
    
    try:
        # è¤‡è£½ Git å€‰åº«
        print(f"Cloning repo from {github_url} into {temp_dir}...")
        subprocess.run(
            ['git', 'clone', '--depth', '1', github_url, temp_dir],
            check=True, capture_output=True, text=True, encoding='utf-8'
        )
        
        # (å¯é¸ï¼Œä½†æ¨è–¦) åˆå§‹åŒ– Gitï¼Œä»¥ä¾¿æˆ‘å€‘å¯ä»¥ 'git diff'
        subprocess.run(['git', 'init'], cwd=temp_dir, check=True, capture_output=True, text=True, encoding='utf-8')
        subprocess.run(['git', 'add', '.'], cwd=temp_dir, check=True, capture_output=True, text=True, encoding='utf-8')
        subprocess.run(['git', 'commit', '-m', 'Initial snapshot', '--allow-empty'], cwd=temp_dir, check=True, capture_output=True, text=True, encoding='utf-8')
        print(f"Workspace initialized at {temp_dir}")
        return temp_dir
        
    except subprocess.CalledProcessError as e:
        raise IOError(f"Failed to clone Git repo: {e.stderr}")
    except Exception as e:
        raise IOError(f"File operation failed: {e}")

# ... (åœ¨ run_agent_attempt æ—é‚Š)

def run_agent_demo_attempt(
    workspace_path: str, 
    model, 
    prompt_text: str
) -> dict:
    """
    (æ­¤å‡½æ•¸ä¿æŒä¸è®Š)
    """
    
    raw_response_text = ""
    final_patch_str = ""
    
    try:
        # é‡ç½®å·¥ä½œå€
        subprocess.run(['git', 'reset', '--hard', 'HEAD'], cwd=workspace_path, capture_output=True, text=True, check=True)
        
        # 1. ç”Ÿæˆç¨‹å¼ç¢¼
        response = model.generate_content(prompt_text)
        raw_response_text = response.text
        
        # 2. è§£æå›æ‡‰
        try:
            modified_files = _parse_v7_response(raw_response_text)
        except Exception as e:
            print(f"ERROR: AI response parsing failed: {e}")
            return {'status': 'APPLY_FAILED', 'patch': '', 'raw_response': raw_response_text}

        # 3. å°‡æ–°å…§å®¹å¯«å…¥æ–‡ä»¶
        for file_path, new_content in modified_files.items():
            try:
                if '..' in file_path: continue
                full_path = os.path.join(workspace_path, file_path)
                os.makedirs(os.path.dirname(full_path), exist_ok=True)
                with open(full_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
            except Exception as e:
                 return {'status': 'APPLY_FAILED', 'patch': '', 'raw_response': raw_response_text}

        # 4. ç”Ÿæˆè£œä¸
        diff_result = subprocess.run(
            ['git', 'diff', '--no-prefix'], 
            cwd=workspace_path, capture_output=True, text=True, check=True, encoding='utf-8'
        )
        final_patch_str = diff_result.stdout
        
        # 5. æˆåŠŸè¿”å› (ä¸é‹è¡Œæ¸¬è©¦)
        return {
            'status': 'COMPLETED', # ç‹€æ…‹ç¸½æ˜¯ COMPLETEDï¼Œå› ç‚ºæ²’æœ‰æ¸¬è©¦
            'patch': final_patch_str,
            'raw_response': raw_response_text,
        }
        
    except Exception as e:
        print(f"FATAL ERROR in run_agent_demo_attempt: {e}")
        return {'status': 'APPLY_FAILED', 'patch': '', 'raw_response': raw_response_text}